# Simple DQN Agent Configuration
# =========================

# Environment settings
grid_size: 4
max_steps: 1000
visualization: false  # Set to true if you want to see visualization during training
random_seed: 42
green_duration: 10

# Traffic patterns
traffic_patterns:
  uniform:
    north_south_rate: 0.3
    east_west_rate: 0.3
  rush_hour:
    north_south_rate: 0.6
    east_west_rate: 0.3
  natural:
    base_arrival: 0.02
    peak_intensity: 2.0
    weekend_intensity: 1.5
    morning_peak: 0.33
    evening_peak: 0.71
    weekend_peak: 0.5

# Agent settings
learning_rate: 0.0005
gamma: 0.99
epsilon_start: 1.0
epsilon_end: 0.01
epsilon_decay: 0.995
buffer_size: 50000
batch_size: 128
hidden_dim: 128
target_update: 10
update_every: 4
device: "auto"

# Training settings
num_episodes: 500
eval_frequency: 100
save_frequency: 100
early_stopping_patience: 20
early_stopping_reward: 10000

# Reward function settings
waiting_time_weight: -1.0
throughput_weight: 1.0
max_waiting_time: 100
reward_scale: 0.01

# Output settings
output:
  model_dir: "models/simple_dqn"
  log_dir: "logs/simple_dqn"
  visualization_dir: "visualizations/simple_dqn" 